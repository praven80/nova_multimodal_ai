import streamlit as st
import json
import base64
import logging
from datetime import datetime
import boto3
from botocore.exceptions import ClientError
from PIL import Image
from botocore.config import Config
import io
import time
import os

# Set up logging
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

# Retrieve the bucket name from environment variable
s3_bucket_name = os.environ.get('S3_BUCKET_NAME')
# s3_bucket_name = "307492694773-q"

if not s3_bucket_name:
    raise ValueError("S3_BUCKET_NAME environment variable is not set")

# Define ImageError exception
class ImageError(Exception):
    """Custom exception for image generation errors."""
    def __init__(self, message):
        self.message = message
        super().__init__(self.message)

# Initialize the Bedrock client
def get_bedrock_client(region="us-east-1"):
    """Create a Bedrock client."""
    return boto3.client("bedrock-runtime", region_name=region)

def generate_presigned_url(bucket_name, object_key, expiration=3600):
    # Create a session using Boto3
    s3_client = boto3.client('s3')
    
    try:
        # Generate a presigned URL for the video file
        presigned_url = s3_client.generate_presigned_url(
            'get_object',
            Params={'Bucket': bucket_name, 'Key': object_key},
            ExpiresIn=expiration  # Time (in seconds) for the link to remain valid
        )
        return presigned_url
    except Exception as e:
        st.write(f"Error generating presigned URL: {e}")
        return None

def check_job_status(invocation_arn):
    # Create the Bedrock Runtime client
    bedrock_runtime = boto3.client("bedrock-runtime")

    try:
        # Get the invocation status
        invocation = bedrock_runtime.get_async_invoke(
            invocationArn=invocation_arn
        )

        # Print the JSON response (for debugging)
        print(json.dumps(invocation, indent=2, default=str))

        status = invocation["status"]
        invocation_arn = invocation["invocationArn"]

        if status == "Completed":
            bucket_uri = invocation["outputDataConfig"]["s3OutputDataConfig"]["s3Uri"]
            folder_path = bucket_uri.lstrip("s3://").split("/", 1)[1]
            file_name = folder_path + "/output.mp4"
            video_object_key = file_name
        
            video_uri = generate_presigned_url(s3_bucket_name, video_object_key)
        
            return "Completed", video_uri

        elif status == "InProgress":
            # Job still in progress
            start_time = invocation["submitTime"]
            print(f"Job {invocation_arn} is still in progress. Started at: {start_time}")
            return "InProgress", None

        elif status == "Failed":
            # Job failed
            failure_message = invocation["failureMessage"]
            print(f"Job {invocation_arn} failed. Failure message: {failure_message}")
            return "Failed", None

    except Exception as e:
        st.write(f"Error fetching status: {str(e)}")
        return "Error", None

def text_to_text_converse(prompt):
    """Text-to-Text Converse function using the Nova model."""
    try:
        client = get_bedrock_client()

        system = [{"text": "You are a helpful assistant"}]
        messages = [{"role": "user", "content": [{"text": prompt}]}]
        inf_params = {"maxTokens": 300, "topP": 0.1, "temperature": 0.3}

        model_response = client.converse(
            modelId="us.amazon.nova-lite-v1:0",
            messages=messages,
            system=system,
            inferenceConfig=inf_params,
        )

        return(model_response['output']['message']['content'][0]['text'])
    except Exception as e:
        st.write("Error in text_to_text_converse:", str(e))
        return

def text_to_image_invoke_model(model_id, body):
    """
    Generate an image using Amazon Nova Canvas model on demand.
    Args:
        model_id (str): The model ID to use.
        body (str): The request body to use.
    Returns:
        image_bytes (bytes): The image generated by the model.
    """

    # logger.info("Generating image with Amazon Nova Canvas model", model_id)

    try:
        bedrock = boto3.client(
            service_name='bedrock-runtime',
            config=Config(read_timeout=300)
        )

        accept = "application/json"
        content_type = "application/json"

        response = bedrock.invoke_model(
            body=body, modelId=model_id, accept=accept, contentType=content_type
        )
        response_body = json.loads(response.get("body").read())

        base64_image = response_body.get("images")[0]
        base64_bytes = base64_image.encode('ascii')
        image_bytes = base64.b64decode(base64_bytes)

        finish_reason = response_body.get("error")

        if finish_reason is not None:
            raise ImageError(f"Image generation error. Error is {finish_reason}")

        logger.info(
            "Successfully generated image with Amazon Nova Canvas model %s", model_id)

        return image_bytes
    except Exception as e:
        st.write("Error in text_to_image_invoke_model:", str(e))
        return

def text_to_video_async_invoke(prompt):
    # Create the Bedrock Runtime client.
    bedrock_runtime = boto3.client("bedrock-runtime")

    model_input = {
        "taskType": "TEXT_VIDEO",
        "textToVideoParams": {
            "text": prompt
        },
        "videoGenerationConfig": {
            "durationSeconds": 6,
            "fps": 24,
            "dimension": "1280x720",
            "seed": 0,  # Change the seed to get a different result
        },
    }
    try:
        # Start the asynchronous video generation job.
        response = bedrock_runtime.start_async_invoke(
            modelId="amazon.nova-reel-v1:0",
            modelInput=model_input,
            outputDataConfig={
                "s3OutputDataConfig": {
                    "s3Uri": f"s3://{s3_bucket_name}/nova/"
                }
            }
        )

        # Get the invocation ARN (unique identifier for the job)
        invocation_arn = response["invocationArn"]
        return invocation_arn

    except Exception as e:
        # Implement error handling here.
        st.write("Error in text_to_video_async_invoke:", str(e))
        return

def image_to_text_invoke_model(image_file):
    try:
        """Image-to-Text invoke model."""
        client = get_bedrock_client()

        MODEL_ID = "us.amazon.nova-lite-v1:0"

        # Convert image to base64 string
        image_bytes = image_file.read()
        base64_string = base64.b64encode(image_bytes).decode("utf-8")

        # Display the uploaded image in the app
        image = Image.open(image_file)
        # st.image(image, caption="Uploaded Image", use_column_width=True)
        st.image(image, caption="Uploaded Image", use_container_width=True)

        system_list = [{"text": "You are an expert artist. When the user provides you with an image, explain the image"}]
        message_list = [
            {
                "role": "user",
                "content": [
                    {"image": {"format": "png", "source": {"bytes": base64_string}}},
                    {"text": "Explain the image"}
                ],
            }
        ]
        inf_params = {"max_new_tokens": 300, "top_p": 0.1, "top_k": 20, "temperature": 0.3}

        native_request = {
            "schemaVersion": "messages-v1",
            "messages": message_list,
            "system": system_list,
            "inferenceConfig": inf_params,
        }

        response = client.invoke_model(modelId=MODEL_ID, body=json.dumps(native_request))
        model_response = json.loads(response["body"].read())
        return model_response['output']['message']['content'][0]['text']
    except Exception as e:
        st.write("Error in image_to_text_invoke_model:", str(e))
        return

def image_to_image_invoke_model(model_id, body):
    """
    Generate an image using Amazon Nova Canvas  model on demand.
    Args:
        model_id (str): The model ID to use.
        body (str) : The request body to use.
    Returns:
        image_bytes (bytes): The image generated by the model.
    """

    try:
        logger.info(
        "Generating image with Amazon Nova Canvas  model %s", model_id)

        bedrock = boto3.client(
            service_name='bedrock-runtime',
            config=Config(read_timeout=300)
        )

        accept = "application/json"
        content_type = "application/json"

        response = bedrock.invoke_model(
            body=body, modelId=model_id, accept=accept, contentType=content_type
        )
        response_body = json.loads(response.get("body").read())

        base64_image = response_body.get("images")[0]
        base64_bytes = base64_image.encode('ascii')
        image_bytes = base64.b64decode(base64_bytes)

        finish_reason = response_body.get("error")

        if finish_reason is not None:
            raise ImageError(f"Image generation error. Error is {finish_reason}")

        logger.info(
            "Successfully generated image with Amazon Nova Canvas  model %s", model_id)

        return image_bytes
    except Exception as e:
        st.write("Error in image_to_image_invoke_model:", str(e))
        return

def image_to_video_async_invoke(image_file, prompt):
    # Create the Bedrock Runtime client
    bedrock_runtime = boto3.client("bedrock-runtime")

    try:
        # Use getvalue() to fetch the image content
        image_bytes = image_file.getvalue()
        
        # Check if image_bytes is empty
        if not image_bytes:
            print("Error: Image file is empty.")
            return
        
        # Convert the image bytes to base64 string
        input_image_base64 = base64.b64encode(image_bytes).decode("utf-8")

        # Check if the base64 string is non-empty
        if not input_image_base64:
            print("Error: Base64 string is empty.")
            return

        # Create the model input
        model_input = {
            "taskType": "TEXT_VIDEO",
            "textToVideoParams": {
                "text": prompt,
                "images": [
                    {
                        "format": "png",  # Specify the format explicitly
                        "source": {
                            "bytes": input_image_base64
                        }
                    }
                ]
            },
            "videoGenerationConfig": {
                "durationSeconds": 6,
                "fps": 24,
                "dimension": "1280x720",
                "seed": 0
            },
        }

        # Start the asynchronous video generation job
        response = bedrock_runtime.start_async_invoke(
            modelId="amazon.nova-reel-v1:0",
            modelInput=model_input,
            outputDataConfig={
                "s3OutputDataConfig": {
                    "s3Uri": f"s3://{s3_bucket_name}/nova/"
                }
            },
        )

        # Get the invocation ARN (unique identifier for the job)
        invocation_arn = response["invocationArn"]
        return invocation_arn

    except Exception as e:
        st.write("Error in image_to_video_async_invoke:", str(e))
        return

def video_to_text_local_file_invoke_model(video_file):
    LITE_MODEL_ID = "us.amazon.nova-lite-v1:0"
    # Create a Bedrock Runtime client in the AWS Region of your choice.
    client = boto3.client(
        "bedrock-runtime",
        region_name="us-east-1",
    )

    MODEL_ID = "us.amazon.nova-lite-v1:0"
    # Read the video file content into memory
    video_bytes = video_file.read()

    # Encode video file to base64 string
    base64_string = base64.b64encode(video_bytes).decode("utf-8")

    # Display the video in Streamlit
    st.video(video_file)
    
    # Define your system prompt(s).
    system_list= [
        {
            "text": "You are an expert media analyst. When the user provides you with a video, explain the video content"
        }
    ]
    # Define a "user" message including both the image and a text prompt.
    message_list = [
        {
            "role": "user",
            "content": [
                {
                    "video": {
                        "format": "mp4",
                        "source": {"bytes": base64_string},
                    }
                },
                {
                    "text": "Explain the video content."
                },
            ],
        }
    ]
    # Configure the inference parameters.
    inf_params = {"max_new_tokens": 300, "top_p": 0.1, "top_k": 20, "temperature": 0.3}

    native_request = {
        "schemaVersion": "messages-v1",
        "messages": message_list,
        "system": system_list,
        "inferenceConfig": inf_params,
    }
    # Invoke the model and extract the response body.
    response = client.invoke_model(modelId=LITE_MODEL_ID, body=json.dumps(native_request))
    model_response = json.loads(response["body"].read())

    content_text = model_response["output"]["message"]["content"][0]["text"]
    return content_text

def main():
    st.title("Amazon Nova - Multimodal Chatbot")

    # Create two columns to display the combo boxes side by side
    col1, col2 = st.columns(2)

    # Display the Input Type Combo Box in the first column
    with col1:
        input_option = st.selectbox("Select Input Type", ["Text", "Image", "Video"])

    # Display the Output Type Combo Box in the second column
    with col2:
        output_option = st.selectbox("Select Output Type", ["Text", "Image", "Video"])

    # Define chat history for a conversational app
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    # Display previous conversation history
    for message in st.session_state.chat_history:
        st.chat_message(message["role"]).markdown(message["content"])

    prompt = None
    input_file = None

    if input_option == "Video" and (output_option == "Image" or output_option == "Video"):
        st.write("Video to Image / Video is not supported yet !!!")

    if input_option == "Text":
        prompt = st.chat_input("Ask me anything:")

    if input_option == "Image":
        input_file = st.file_uploader("Upload an Image", type=["png"])

        if input_file is not None:

            # Process Image -> Text output
            if output_option == "Text":
                model_response = image_to_text_invoke_model(input_file)
                response = model_response
                st.write(model_response)

            # Process Image -> Image OR Image -> Video output
            elif output_option == "Image" or output_option == "Video":
                # Display the uploaded image in the app
                image = Image.open(input_file)
                # st.image(image, caption="Uploaded Image", use_column_width=True)
                st.image(image, caption="Uploaded Image", use_container_width=True)

    elif input_option == "Video" and output_option == "Text":
        input_file = st.file_uploader("Upload a Video", type=["mp4", "avi", "mov"])

        if input_file is not None:
            model_response = video_to_text_local_file_invoke_model(input_file)
            response = model_response
            st.write(model_response)

    if input_option == "Image" and (output_option == "Image" or output_option == "Video") and input_file is not None:
        prompt = st.chat_input("Enter a prompt to modify the image / video:")

    if prompt:
        # Clear chat history after every prompt
        st.session_state.chat_history = []

        # Add user message to chat history
        st.session_state.chat_history.append({"role": "user", "content": prompt})

         # Process Text -> Text output
        if input_option == "Text" and output_option == "Text":
            model_response = text_to_text_converse(prompt)
            response = model_response

        # Process Text -> Image output
        elif input_option == "Text" and output_option == "Image":
            model_id = 'amazon.nova-canvas-v1:0'
            body = json.dumps({
                "taskType": "TEXT_IMAGE",
                "textToImageParams": {"text": prompt},
                "imageGenerationConfig": {"numberOfImages": 1, "height": 1024, "width": 1024, "cfgScale": 8.0, "seed": 0}
            })

            try:
                image_bytes = text_to_image_invoke_model(model_id=model_id, body=body)
                image = Image.open(io.BytesIO(image_bytes))
                # st.image(image, caption="Generated Image", use_column_width=True)
                st.image(image, caption="Generated Image", use_container_width=True)
                response = "Image has been generated."

            except ClientError as err:
                message = err.response["Error"]["Message"]
                st.error(f"A client error occurred: {message}")
                response = "Error occurred while generating image."

        # Process Text -> Video output
        elif input_option == "Text" and output_option == "Video":
            invocation_arn = text_to_video_async_invoke(prompt)
            if invocation_arn:
                st.write("The video generation process is underway. Please allow approximately 5 minutes for completion.")

                # Check job status every 10 seconds until completed
                while True:
                    status, video_uri = check_job_status(invocation_arn)

                    if status == "Completed":
                        # Job completed successfully, display the video
                        st.write(f"Video is ready! You can view it [here]({video_uri})")
                        st.video(video_uri)  # Display the video
                        response = "Video has been generated."
                        break

                    elif status == "InProgress":
                        # Job is still in progress, wait and check again
                        time.sleep(10)

                    elif status == "Failed":
                        # Job failed
                        st.error("Video generation failed.")
                        break

                    else:
                        # An unexpected error occurred
                        st.error("An unexpected error occurred.")
                        break
            # response = "Video is getting generated !!!"

        # Process Image -> Image output when prompt is provided
        if input_option == "Image" and output_option == "Image":
            try:
                logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")

                model_id = 'amazon.nova-canvas-v1:0'

                # Check if the file is uploaded correctly
                if input_file is not None:

                    # Read image bytes using getvalue() method instead of read()
                    img_bytes = input_file.getvalue()

                    # If the byte length is 0, raise an error
                    if len(img_bytes) == 0:
                        raise ValueError("Uploaded image is empty.")
                else:
                    raise ValueError("No image file uploaded.")

                # Convert the image to base64
                input_image = base64.b64encode(img_bytes).decode('utf-8')

                if not input_image:
                    raise ValueError("Image encoding failed. The base64 string is empty.")

                body = json.dumps({
                    "taskType": "IMAGE_VARIATION",
                    "imageVariationParams": {
                        "text": prompt,  # The user-provided prompt
                        "negativeText": "bad quality, low resolution, cartoon",
                        "images": [input_image],  # Correctly put the base64 image in the list
                        "similarityStrength": 0.7,  # Range: 0.2 to 1.0
                    },
                    "imageGenerationConfig": {
                        "numberOfImages": 1,
                        "height": 512,
                        "width": 512,
                        "cfgScale": 8.0
                    }
                })

                # Invoke the model to get the generated image
                image_bytes = image_to_image_invoke_model(model_id=model_id, body=body)
                generated_image = Image.open(io.BytesIO(image_bytes))

                # Display the generated image within Streamlit
                # st.image(generated_image, caption="Generated Image", use_column_width=True)
                st.image(generated_image, caption="Generated Image", use_container_width=True)
                response = "Image has been generated."

            except Exception as e:
                st.error(f"An unexpected error occurred: {e}")
                response = "Error occurred while generating image."

        # Process Image -> Video output when prompt is provided
        if input_option == "Image" and output_option == "Video":
            try:
                logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
                invocation_arn = image_to_video_async_invoke(input_file, prompt)
                if invocation_arn:
                    st.write("The video generation process is underway. Please allow approximately 5 minutes for completion.")

                    # Check job status every 10 seconds until completed
                    while True:
                        status, video_uri = check_job_status(invocation_arn)

                        if status == "Completed":
                            # Job completed successfully, display the video
                            st.write(f"Video is ready! You can view it [here]({video_uri})")
                            st.video(video_uri)  # Display the video
                            response = "Video has been generated."
                            break

                        elif status == "InProgress":
                            # Job is still in progress, wait and check again
                            time.sleep(10)

                        elif status == "Failed":
                            # Job failed
                            st.error("Video generation failed.")
                            break

                        else:
                            # An unexpected error occurred
                            st.error("An unexpected error occurred.")
                            break

                # model_response = image_to_video_async_invoke(input_file, prompt)
                # response = "Video is getting generated !!!"

            except Exception as e:
                st.error(f"An unexpected error occurred: {e}")
                response = "Error occurred while generating video."

        # Process Video -> Text output
        elif input_option == "Video" and output_option == "Text" and input_file:
            model_response = video_to_text_local_file_invoke_model(input_file)
            response = model_response

        # Add bot's response to chat history
        st.session_state.chat_history.append({"role": "assistant", "content": response})

    # Display bot's response after it is added to chat history
    for message in st.session_state.chat_history:
        st.chat_message(message["role"]).markdown(message["content"])

    st.session_state.chat_history = []
if __name__ == "__main__":
    main()